**                                                  # Meta Product Analytics â€” Data Engineering Project
**

[![dbt](https://img.shields.io/badge/dbt-v1.10.13-brightgreen)](https://www.getdbt.com/)
[![Python](https://img.shields.io/badge/Python-3.12-blue)](https://www.python.org/)
[![DuckDB](https://img.shields.io/badge/DuckDB-embedded%20OLAP-orange)](https://duckdb.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)



# Meta Product Analytics â€” Data Engineering Project

End-to-end analytics pipeline using **dbt + DuckDB + Python** to simulate a Meta-style product analytics workflow (Raw â†’ Staging â†’ Marts â†’ KPI dashboards). Includes lineage, tests, docs, and reproducible local runs.

---

## ğŸš€ Highlights
- **Modern stack:** dbt (models/tests/docs) + **DuckDB** (local OLAP) + Python utilities  
- **Medallion layers:** `raw` â†’ `staging` â†’ `marts` with reusable macros & sources  
- **Product analytics focus:** DAU/MAU, retention, engagement, feature adoption, funnel KPIs  
- **Quality built-in:** dbt tests (unique/not null/relationships) + freshness checks  
- **Docs & lineage:** auto-generated dbt docs with DAG/graph views  
- **Optional BI:** export parquet/CSV for **Power BI/Tableau** dashboards  

---

## ğŸ“‚ Repository Structure
meta_product_analytics_de_project/
â”œâ”€ data/
â”‚ â””â”€ raw/
â”œâ”€ models/
â”‚ â”œâ”€ raw/
â”‚ â”œâ”€ staging/
â”‚ â””â”€ marts/
â”‚ â”œâ”€ core/
â”‚ â””â”€ product_analytics/
â”œâ”€ infra/
â”œâ”€ logs/
â”œâ”€ target/
â”œâ”€ schema.yml
â”œâ”€ dbt_project.yml
â”œâ”€ profiles.yml
â”œâ”€ warehouse.duckdb
â”œâ”€ README.md
â””â”€ images/
â”œâ”€ dbt_lineage.png
â””â”€ fct_returns_summary.png


---

## ğŸ§° Prerequisites
- Python 3.10+  
- `pipx` or `pip`  
- dbt-duckdb: `pip install dbt-duckdb`  
- (Optional) Power BI / Tableau for dashboards  

---

## âš™ï¸ Quickstart
```bash
# 1) Clone the repository
git clone https://github.com/Kurapati1309/meta_product_analytics_de_project.git
cd meta_product_analytics_de_project

# 2) Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate

# 3) Install dependencies
pip install -r requirements.txt  # if available
pip install dbt-duckdb duckdb pandas pyarrow

# 4) Verify dbt installation
dbt --version

# 5) Run models and tests
dbt run
dbt test

# 6) Generate documentation
dbt docs generate
dbt docs serve   # open http://localhost:8080

ğŸ§± Data Model (Medallion Architecture)

Raw: external sources (CSV, JSON, APIs, etc.)

Staging: type casting, deduplication, column standardization (user_id, event_time, event_type)

Marts:

core/: dim_users, fct_events, fct_sessions

product_analytics/: dau_mau, retention_cohorts, feature_adoption, engagement_kpis, funnel_steps

ğŸ“Š KPIs & Metrics

DAU / MAU ratio

Retention cohorts (D1/D7/D30)

Engagement (events per user, session duration)

Feature adoption & funnel conversion

Each KPI model includes dbt tests for integrity:

unique

not_null

relationships

ğŸ–¼ï¸ Lineage & Documentation

Visuals included under /images/:
![dbt Lineage](images/dbt_lineage.png)
![Fact Table Summary](images/fct_returns_summary.png)

To generate interactive docs:
dbt docs generate
dbt docs serve

ğŸ§ª Data Quality & Freshness

Automated data tests ensure schema consistency and reliability.

Freshness checks configured via sources.yml using loaded_at_field.

Relationship tests maintain referential integrity (e.g., fct_events.user_id â†’ dim_users.user_id).

ğŸ“¤ Export for BI

Export analytics-ready marts for Power BI or Tableau:
COPY (SELECT * FROM product_analytics.dau_mau)
TO 'exports/dau_mau.parquet' (FORMAT PARQUET);

Suggested dashboards:

DAU & MAU trends

Retention heatmap (D1, D7, D30)

Funnel conversion steps

Feature adoption over time
ğŸ” CI/CD (Optional Setup)

Integrate with GitHub Actions or any CI pipeline:
- name: Build and Test dbt
  run: |
    dbt deps
    dbt build
    dbt docs generate

ğŸ§  Why This Project (Meta-style)

This project mirrors Metaâ€™s Product Analytics framework â€” focusing on:

Experimentation readiness

Scalable KPI modeling

Data quality automation

User engagement insights

It demonstrates real-world data engineering and analytics integration with modern open-source tools.

ğŸ“¦ requirements.txt
dbt-duckdb
duckdb
pandas
pyarrow
sqlfluff

ğŸ§© profiles.yml (DuckDB Local Target)
meta_product_analytics_de_project:
  outputs:
    dev:
      type: duckdb
      path: warehouse.duckdb
      schema: main
  target: dev

## ğŸ‘¨â€ğŸ’» Author & Credits

**Hemanth Kumar Kurapati**
Founder â€” Moonlight Aura Data Warehouse
ğŸ“ Houston, TX
âœ‰ï¸ [hk485@nau.edu](mailto:hk485@nau.edu)
ğŸ”— [LinkedIn](https://www.linkedin.com/in/hemanth-kurapati1021)
ğŸ”— [GitHub](https://github.com/Kurapati1309)

